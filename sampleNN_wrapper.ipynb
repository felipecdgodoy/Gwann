{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "REQUIRED INSTALLS:\n",
    "\n",
    "import sys\n",
    "!{sys.executable} -m pip install tensorflow==2.0.0-rc1 --user\n",
    "\n",
    "import sys\n",
    "!{sys.executable} -m pip install keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "REQUIRED IMPORTS:\n",
    "\n",
    "* import numpy as np\n",
    "* import tensorflow as tf\n",
    "* from keras.models import Sequential\n",
    "* from keras.layers import Convolution2D\n",
    "* from keras.layers import MaxPooling2D\n",
    "* from keras.layers import Flatten\n",
    "* from keras.layers import Dense\n",
    "* from keras.preprocessing.image import ImageDataGenerator\n",
    "* from keras.preprocessing import image\n",
    "* from IPython.display import display\n",
    "* from PIL import Image\n",
    "* import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFilesFromDir(path, extension): #ext should include '.', such as '.jpg'\n",
    "    import os\n",
    "    fileList = []\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for filename in files:\n",
    "            if filename[-len(extension):] == extension: # gets the extension from filename and compares it\n",
    "                fileList.append(filename)\n",
    "    return fileList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def performTrainingDataAugmentation(): #Re-visit!!!\n",
    "    from keras.preprocessing.image import ImageDataGenerator\n",
    "    return ImageDataGenerator(\n",
    "    rescale = 1./255,\n",
    "    shear_range = 0.2,\n",
    "    zoom_range = 0.2,\n",
    "    horizontal_flip = True)\n",
    "\n",
    "def performTestingDataAugmentation(): #Re-visit!!!\n",
    "    from keras.preprocessing.image import ImageDataGenerator\n",
    "    return ImageDataGenerator(rescale = 1./255)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_TrainingSet(path):\n",
    "    train_datagen = performTrainingDataAugmentation()\n",
    "    return train_datagen.flow_from_directory(\n",
    "    path,\n",
    "    target_size = (64, 64),\n",
    "    batch_size = 32,\n",
    "    class_mode = 'binary')\n",
    "    \n",
    "def setup_TestingSet(path):\n",
    "    test_datagen = performTestingDataAugmentation()\n",
    "    return test_datagen.flow_from_directory(\n",
    "    path,\n",
    "    target_size = (64, 64),\n",
    "    batch_size = 32,\n",
    "    class_mode = 'binary')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_Classifier(classifier_type, activ, metricsArray):\n",
    "    import tensorflow as tf\n",
    "    from keras.models import Sequential\n",
    "    from keras.layers import Convolution2D\n",
    "    from keras.layers import MaxPooling2D\n",
    "    from keras.layers import Flatten\n",
    "    from keras.layers import Dense\n",
    "    clasf = Sequential()    # Step 0: Create the classifier\n",
    "    clasf.add(Convolution2D(32, 3, 3, input_shape = (64, 64, 3), activation = 'relu')) # Step 1: Convolution: extract features from image input\n",
    "    clasf.add(MaxPooling2D(pool_size = (2, 2))) # Step 2: Pooling: dimentionality reduction\n",
    "    clasf.add(Flatten()) # Step 3: Flattening: dimentionally-reduced matrix is converted to linear array for single-element outputing\n",
    "    clasf.add(Dense(activation = 'relu', units = 128))\n",
    "    clasf.add(Dense(activation = 'sigmoid', units = 1))\n",
    "    clasf.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    return clasf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictions(classifier, path, extension, outputA, outputB):\n",
    "    import numpy as np\n",
    "    from keras.preprocessing import image\n",
    "    predList = []\n",
    "    for filename in getFilesFromDir(path, extension):\n",
    "        test_image = image.load_img((path + '/' + filename), target_size = (64, 64)) #concatenates Gwann/img and random.jpg together\n",
    "        test_image = image.img_to_array(test_image)\n",
    "        test_image = np.expand_dims(test_image, axis = 0)\n",
    "        result = classifier.predict(test_image)\n",
    "        training_set.class_indices\n",
    "        if result[0][0] >= 0.5:\n",
    "            predList.append((outputA, result[0][0]))\n",
    "        else:\n",
    "            predList.append((outputB, result[0][0]))\n",
    "    return predList\n",
    "\n",
    "def results(classifier, path, extension, outputA, outputB):\n",
    "    predList = predictions(classifier, path, extension, outputA, outputB)\n",
    "    correct = 0\n",
    "    for predTuple in predList: # predTuple = (output, confidence)\n",
    "        print(\"conf: \" + str(predTuple[1]))\n",
    "        if predTuple[0] == outputA:\n",
    "            print(\"Believed to be: \" + outputA + \". Confidence: \" + str(predTuple[1]))\n",
    "            correct += 1\n",
    "        else:\n",
    "            print(\"Believed to be: \" + outputB + \". Confidence: \" + str(predTuple[1]))\n",
    "    print(\"Accuracy: \" + str(round((100.0 * (correct / len(predList))), 3)) + '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainModel(classif_type, activ, metricsArr, training_set, numEpochs, stepsPerEpoch, testing_set, validationSteps):\n",
    "    from IPython.display import display\n",
    "    from PIL import Image\n",
    "    clasf = setup_Classifier(classif_type, activ, metricsArr)\n",
    "    clasf.fit_generator(\n",
    "        training_set,\n",
    "        steps_per_epoch = stepsPerEpoch,\n",
    "        epochs = numEpochs,\n",
    "        validation_data = testing_set,\n",
    "        validation_steps = validationSteps\n",
    "    )\n",
    "    return clasf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Running through Hot-Dog / Not Hot-Dog example with wrapper_:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 498 images belonging to 2 classes.\n",
      "Found 500 images belonging to 2 classes.\n",
      "Epoch 1/4\n",
      "30/30 [==============================] - 7s 237ms/step - loss: 0.9563 - accuracy: 0.5000 - val_loss: 0.7350 - val_accuracy: 0.5398\n",
      "Epoch 2/4\n",
      "30/30 [==============================] - 7s 243ms/step - loss: 0.6180 - accuracy: 0.6524 - val_loss: 0.6925 - val_accuracy: 0.5669\n",
      "Epoch 3/4\n",
      "15/30 [==============>...............] - ETA: 2s - loss: 0.5957 - accuracy: 0.6953"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "training_set = setup_TrainingSet('Gwann/seefood/train')\n",
    "testing_set = setup_TestingSet('Gwann/seefood/test') # ResNet50\n",
    "model = trainModel('Sequential', 'relu', ['accuracy'], training_set, 4, 30, testing_set, 20)\n",
    "results(model, 'Gwann/seefood/test/hot_dog', '.jpg', 'Hot Dog', 'Not Hot Dog')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
