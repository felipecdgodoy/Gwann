{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.3"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "Using TensorFlow backend.\n"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.layers import Dense, Conv2D, BatchNormalization, Dropout, Flatten\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from itertools import combinations\n",
    "import timeit\n",
    "import _thread\n",
    "import multiprocessing\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#turns str glich name into a 1 or 0\n",
    "def gliches_get_stiches(aList,glich):\n",
    "    new_list = []\n",
    "    for i in range(len(aList)):\n",
    "        if aList[i] == glich:\n",
    "            new_list += [1]\n",
    "        else:\n",
    "            new_list += [0]\n",
    "    return np.array(new_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_da_gliches(aList):\n",
    "    new_list = []\n",
    "    \n",
    "    labels = data['label'].unique()\n",
    "    for i in range(len(aList)):\n",
    "        zeros = np.zeros(22)\n",
    "        for x in range(len(labels)):\n",
    "            if aList[i] == labels[x]:\n",
    "                zeros[x] = 1\n",
    "\n",
    "        new_list += [zeros]\n",
    "    return np.array(new_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "6787\n"
    }
   ],
   "source": [
    "data = pd.read_csv('trainingset_v1d1_metadata.csv')\n",
    "#data2 = data[data['label'] !='None_of_the_Above']\n",
    "#glich to test\n",
    "glich = 'Whistle'\n",
    "\n",
    "#what features do we want \n",
    "column_selection = [\"duration\",\"peak_frequency\",\"central_freq\",\"amplitude\",\"snr\",\"bandwidth\"]\n",
    "#[\"duration\",\"peak_frequency\",\"central_freq\",\"snr\"]\n",
    "\n",
    "\n",
    "\n",
    "#training data\n",
    "data_train = data[data['sample_type'] == 'train' ] \n",
    "glich_list = data_train['label'].tolist()\n",
    "y_train = all_da_gliches(glich_list)\n",
    "x_train = np.array(data_train[column_selection])\n",
    "#print(len(x_train))\n",
    "#testing data\n",
    "data_test = data[data['sample_type'] == 'test']\n",
    "glich_list2 = data_test['label'].tolist()\n",
    "y_test = all_da_gliches(glich_list2)\n",
    "x_test = np.array(data_test[column_selection])\n",
    "\n",
    "#validation data\n",
    "data_val = data[data['sample_type'] == 'validation']\n",
    "glich_list3 = data_val['label'].tolist()\n",
    "y_val = all_da_gliches(glich_list3)\n",
    "x_val = np.array(data_val[column_selection])\n",
    "#print(data_test[column_selection])\n",
    "x_train= np.array(list(x_train) + list(x_val))\n",
    "y_train= np.array(list(y_train) + list(y_val))\n",
    "print(len(x_train))\n",
    "#print(data[data['label'] !='None_of_the_Above'])\n",
    "#np.where(pd.isnull(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "EOL while scanning string literal (<ipython-input-25-d2ca528554c2>, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-25-d2ca528554c2>\"\u001b[1;36m, line \u001b[1;32m4\u001b[0m\n\u001b[1;33m    if x == \"\\\":\u001b[0m\n\u001b[1;37m                ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m EOL while scanning string literal\n"
     ]
    }
   ],
   "source": [
    "#pystrain_data = pd.read_csv('ihspin_hn_0.asc')\n",
    "#for i in range(len(pystrain_data)):\n",
    "#    for x in pystrain_data[i]:\n",
    "#        if x == \"\\\":\n",
    "#            x = ','\n",
    "\n",
    "#np.array(pystrain_data.iloc[:,[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>event_time</th>\n      <th>ifo</th>\n      <th>peak_time</th>\n      <th>peak_time_ns</th>\n      <th>start_time</th>\n      <th>start_time_ns</th>\n      <th>duration</th>\n      <th>search</th>\n      <th>process_id</th>\n      <th>event_id</th>\n      <th>...</th>\n      <th>chisq_dof</th>\n      <th>param_one_name</th>\n      <th>param_one_value</th>\n      <th>gravityspy_id</th>\n      <th>label</th>\n      <th>sample_type</th>\n      <th>url1</th>\n      <th>url2</th>\n      <th>url3</th>\n      <th>url4</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>1.134216e+09</td>\n      <td>L1</td>\n      <td>1134216192</td>\n      <td>931639909</td>\n      <td>1134216192</td>\n      <td>832031011</td>\n      <td>0.18750</td>\n      <td>Omicron</td>\n      <td>0</td>\n      <td>21</td>\n      <td>...</td>\n      <td>0</td>\n      <td>phase</td>\n      <td>-2.72902</td>\n      <td>zmIdpucyOG</td>\n      <td>Whistle</td>\n      <td>train</td>\n      <td>https://panoptes-uploads.zooniverse.org/produc...</td>\n      <td>https://panoptes-uploads.zooniverse.org/produc...</td>\n      <td>https://panoptes-uploads.zooniverse.org/produc...</td>\n      <td>https://panoptes-uploads.zooniverse.org/produc...</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>1.129360e+09</td>\n      <td>L1</td>\n      <td>1129359781</td>\n      <td>558593034</td>\n      <td>1129359781</td>\n      <td>47851085</td>\n      <td>0.94238</td>\n      <td>Omicron</td>\n      <td>0</td>\n      <td>107</td>\n      <td>...</td>\n      <td>0</td>\n      <td>phase</td>\n      <td>1.10682</td>\n      <td>zWFRqqDxwv</td>\n      <td>Whistle</td>\n      <td>test</td>\n      <td>https://panoptes-uploads.zooniverse.org/produc...</td>\n      <td>https://panoptes-uploads.zooniverse.org/produc...</td>\n      <td>https://panoptes-uploads.zooniverse.org/produc...</td>\n      <td>https://panoptes-uploads.zooniverse.org/produc...</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1.127425e+09</td>\n      <td>L1</td>\n      <td>1127425468</td>\n      <td>976317882</td>\n      <td>1127425468</td>\n      <td>960937023</td>\n      <td>0.04688</td>\n      <td>Omicron</td>\n      <td>0</td>\n      <td>218</td>\n      <td>...</td>\n      <td>0</td>\n      <td>phase</td>\n      <td>-0.83099</td>\n      <td>zKCTakFVcf</td>\n      <td>Whistle</td>\n      <td>train</td>\n      <td>https://panoptes-uploads.zooniverse.org/produc...</td>\n      <td>https://panoptes-uploads.zooniverse.org/produc...</td>\n      <td>https://panoptes-uploads.zooniverse.org/produc...</td>\n      <td>https://panoptes-uploads.zooniverse.org/produc...</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>1.132637e+09</td>\n      <td>L1</td>\n      <td>1132636755</td>\n      <td>365233898</td>\n      <td>1132636754</td>\n      <td>951172113</td>\n      <td>0.82422</td>\n      <td>Omicron</td>\n      <td>0</td>\n      <td>88</td>\n      <td>...</td>\n      <td>0</td>\n      <td>phase</td>\n      <td>0.76242</td>\n      <td>z14BdoiFZS</td>\n      <td>Whistle</td>\n      <td>validation</td>\n      <td>https://panoptes-uploads.zooniverse.org/produc...</td>\n      <td>https://panoptes-uploads.zooniverse.org/produc...</td>\n      <td>https://panoptes-uploads.zooniverse.org/produc...</td>\n      <td>https://panoptes-uploads.zooniverse.org/produc...</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>1.132036e+09</td>\n      <td>L1</td>\n      <td>1132035853</td>\n      <td>197264909</td>\n      <td>1132035852</td>\n      <td>933837890</td>\n      <td>2.00366</td>\n      <td>Omicron</td>\n      <td>0</td>\n      <td>16</td>\n      <td>...</td>\n      <td>0</td>\n      <td>phase</td>\n      <td>-0.31161</td>\n      <td>yyjqLCtAmO</td>\n      <td>Whistle</td>\n      <td>validation</td>\n      <td>https://panoptes-uploads.zooniverse.org/produc...</td>\n      <td>https://panoptes-uploads.zooniverse.org/produc...</td>\n      <td>https://panoptes-uploads.zooniverse.org/produc...</td>\n      <td>https://panoptes-uploads.zooniverse.org/produc...</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 28 columns</p>\n</div>",
      "text/plain": "     event_time ifo   peak_time  peak_time_ns  start_time  start_time_ns  \\\n0  1.134216e+09  L1  1134216192     931639909  1134216192      832031011   \n1  1.129360e+09  L1  1129359781     558593034  1129359781       47851085   \n2  1.127425e+09  L1  1127425468     976317882  1127425468      960937023   \n3  1.132637e+09  L1  1132636755     365233898  1132636754      951172113   \n4  1.132036e+09  L1  1132035853     197264909  1132035852      933837890   \n\n   duration   search  process_id  event_id  ...  chisq_dof  param_one_name  \\\n0   0.18750  Omicron           0        21  ...          0           phase   \n1   0.94238  Omicron           0       107  ...          0           phase   \n2   0.04688  Omicron           0       218  ...          0           phase   \n3   0.82422  Omicron           0        88  ...          0           phase   \n4   2.00366  Omicron           0        16  ...          0           phase   \n\n   param_one_value gravityspy_id    label  sample_type  \\\n0         -2.72902    zmIdpucyOG  Whistle        train   \n1          1.10682    zWFRqqDxwv  Whistle         test   \n2         -0.83099    zKCTakFVcf  Whistle        train   \n3          0.76242    z14BdoiFZS  Whistle   validation   \n4         -0.31161    yyjqLCtAmO  Whistle   validation   \n\n                                                url1  \\\n0  https://panoptes-uploads.zooniverse.org/produc...   \n1  https://panoptes-uploads.zooniverse.org/produc...   \n2  https://panoptes-uploads.zooniverse.org/produc...   \n3  https://panoptes-uploads.zooniverse.org/produc...   \n4  https://panoptes-uploads.zooniverse.org/produc...   \n\n                                                url2  \\\n0  https://panoptes-uploads.zooniverse.org/produc...   \n1  https://panoptes-uploads.zooniverse.org/produc...   \n2  https://panoptes-uploads.zooniverse.org/produc...   \n3  https://panoptes-uploads.zooniverse.org/produc...   \n4  https://panoptes-uploads.zooniverse.org/produc...   \n\n                                                url3  \\\n0  https://panoptes-uploads.zooniverse.org/produc...   \n1  https://panoptes-uploads.zooniverse.org/produc...   \n2  https://panoptes-uploads.zooniverse.org/produc...   \n3  https://panoptes-uploads.zooniverse.org/produc...   \n4  https://panoptes-uploads.zooniverse.org/produc...   \n\n                                                url4  \n0  https://panoptes-uploads.zooniverse.org/produc...  \n1  https://panoptes-uploads.zooniverse.org/produc...  \n2  https://panoptes-uploads.zooniverse.org/produc...  \n3  https://panoptes-uploads.zooniverse.org/produc...  \n4  https://panoptes-uploads.zooniverse.org/produc...  \n\n[5 rows x 28 columns]"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "[0.8015267175572519, 0.8032230703986429, 0.8023748939779474, 0.816793893129771]\nAccuracy: 0.8388464800678541\n"
    }
   ],
   "source": [
    "def multi_model_trial(some_data, est):\n",
    "    model3 = RandomForestClassifier(n_estimators= est)\n",
    "    keep = []\n",
    "    #feature_list = list(combinations(some_data,3)) + list(combinations(some_data,4)) + list(combinations(some_data,5)) + list(combinations(some_data,6))\n",
    "    feature_list =  list(combinations(some_data,4)) + list(combinations(some_data,5)) + list(combinations(some_data,6))\n",
    "\n",
    "    for i in feature_list:\n",
    "        \n",
    "        x_train = np.array(list(np.array(data_train[np.array(i)])) + list(np.array(data_val[np.array(i)])))\n",
    "        scaler = StandardScaler().fit(x_train)\n",
    "        standardized_X = scaler.transform(x_train)\n",
    "        scaler2 = Normalizer().fit(standardized_X)\n",
    "        std_and_norm_X_train = scaler2.transform(standardized_X)\n",
    "        \n",
    "        x_test = np.array(data_test[np.array(i)])\n",
    "        standardized_X_test = scaler.transform(x_test)\n",
    "        std_and_norm_X_test = scaler2.transform(standardized_X_test)\n",
    "\n",
    "        #no change\n",
    "        #model3.fit(x_train, y_train)\n",
    "        #y_predict = model3.predict(x_test)\n",
    "        \n",
    "        #std \n",
    "        model3.fit(standardized_X, y_train)\n",
    "        y_predict = model3.predict(standardized_X_test)\n",
    "        \n",
    "        #std and norm\n",
    "        #model3.fit(std_and_norm_X_train, y_train)\n",
    "        #y_predict = model3.predict(std_and_norm_X_test)\n",
    "\n",
    "        keep += [y_predict]\n",
    "    return keep\n",
    "\n",
    "#get the models\n",
    "the_models2 = multi_model_trial(column_selection,10)\n",
    "\n",
    "#only keep the top models\n",
    "better_model2 = []\n",
    "for i in the_models2:\n",
    "       if metrics.accuracy_score(y_test, i) > .8:\n",
    "              better_model2.append(i)\n",
    "\n",
    "#I did this because I'm to lazy to change vars\n",
    "keep2 = []\n",
    "for i in better_model2:\n",
    "    keep2.append(metrics.accuracy_score(y_test, i))\n",
    "print(keep2)\n",
    "\n",
    "\n",
    "final2 = []\n",
    "for i in range(len(better_model2[0])):\n",
    "       keep2 = np.zeros(22)\n",
    "       for x in range(len(better_model2)):\n",
    "              keep2 += better_model2[x][i]\n",
    "       for i in range(len(keep2)):\n",
    "              if keep2[i] == max(keep2):\n",
    "                     keep2[i] = 1\n",
    "              else:\n",
    "                     keep2[i] = 0\n",
    "       final2.append(keep2)\n",
    "final_array2 = np.array(final2)\n",
    "\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, final_array2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "0.62 ('duration', 'peak_frequency', 'central_freq', 'amplitude')\n0.63 ('duration', 'peak_frequency', 'central_freq', 'snr')\n0.7 ('duration', 'peak_frequency', 'central_freq', 'bandwidth')\n0.71 ('duration', 'peak_frequency', 'amplitude', 'snr')\n0.71 ('duration', 'peak_frequency', 'amplitude', 'bandwidth')\n[0.6181506849315068, 0.6267123287671232, 0.702054794520548, 0.7123287671232876, 0.7097602739726028]\nAccuracy: 0.7174657534246576\n"
    }
   ],
   "source": [
    "better_model2 = []\n",
    "#feature_list = list(combinations(column_selection,3)) + list(combinations(column_selection,4)) + list(combinations(column_selection,5))\n",
    "feature_list =  list(combinations(column_selection,4)) + list(combinations(column_selection,5)) + list(combinations(column_selection,6)) \n",
    "num = 0\n",
    "for i in the_models2:\n",
    "    if metrics.accuracy_score(y_test, i) > .5:\n",
    "        better_model2.append(i)\n",
    "        print(round(metrics.accuracy_score(y_test, i),2),feature_list[num])\n",
    "    num += 1\n",
    "\n",
    "keep2 = []\n",
    "#better_model2 = better_model2[:2]\n",
    "for i in better_model2:\n",
    "    keep2.append(metrics.accuracy_score(y_test, i))\n",
    "print(keep2)\n",
    "final2 = []\n",
    "for i in range(len(better_model2[0])):\n",
    "       keep2 = np.zeros(22)\n",
    "       for x in range(len(better_model2)):\n",
    "              keep2 += better_model2[x][i]\n",
    "       for i in range(len(keep2)):\n",
    "              if keep2[i] == max(keep2):\n",
    "                     keep2[i] = 1\n",
    "              else:\n",
    "                     keep2[i] = 0\n",
    "       final2.append(keep2)\n",
    "final_array2 = np.array(final2)\n",
    "\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, final_array2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "[0.836472602739726, 0.8398972602739726, 0.8407534246575342, 0.8458904109589042, 0.8373287671232876]\nAccuracy: 0.8613013698630136\n"
    }
   ],
   "source": [
    "def multi_model_trial2(some_data):\n",
    "    model3 = RandomForestClassifier(n_estimators= 100)\n",
    "    keep = []\n",
    "    feature_list= [['duration', 'peak_frequency', 'central_freq', 'snr'],\n",
    "                    ['duration', 'peak_frequency', 'snr', 'bandwidth'],\n",
    "                    ['duration', 'peak_frequency', 'central_freq', 'amplitude', 'snr'],\n",
    "                    ['duration', 'peak_frequency', 'amplitude', 'snr', 'bandwidth'],\n",
    "                    ['duration', 'peak_frequency', 'central_freq', 'amplitude', 'snr', 'bandwidth']]\n",
    "    #feature_list = list(combinations(some_data,3)) + list(combinations(some_data,4)) + list(combinations(some_data,5)) + list(combinations(some_data,6))\n",
    "    #feature_list =  list(combinations(some_data,4)) + list(combinations(some_data,5)) + list(combinations(some_data,6))\n",
    "\n",
    "    for i in feature_list:\n",
    "        \n",
    "        x_train = np.array(list(np.array(data_train[np.array(i)])) + list(np.array(data_val[np.array(i)])))\n",
    "        scaler = StandardScaler().fit(x_train)\n",
    "        standardized_X = scaler.transform(x_train)\n",
    "        scaler2 = Normalizer().fit(standardized_X)\n",
    "        std_and_norm_X_train = scaler2.transform(standardized_X)\n",
    "        \n",
    "        x_test = np.array(data_test[np.array(i)])\n",
    "        standardized_X_test = scaler.transform(x_test)\n",
    "        std_and_norm_X_test = scaler2.transform(standardized_X_test)\n",
    "\n",
    "        #no change\n",
    "        #model3.fit(x_train, y_train)\n",
    "        #y_predict = model3.predict(x_test)\n",
    "        \n",
    "        #std \n",
    "        model3.fit(standardized_X, y_train)\n",
    "        #y_predict = model3.predict(standardized_X_test)\n",
    "        \n",
    "        #std and norm\n",
    "        #model3.fit(std_and_norm_X_train, y_train)\n",
    "        #y_predict = model3.predict(std_and_norm_X_test)\n",
    "\n",
    "        keep += [y_predict]\n",
    "    return keep\n",
    "the_models2 = multi_model_trial2(column_selection)\n",
    "better_model2 = []\n",
    "for i in the_models2:\n",
    "       if metrics.accuracy_score(y_test, i) > .8:\n",
    "              better_model2.append(i)\n",
    "keep2 = []\n",
    "for i in better_model2:\n",
    "    keep2.append(metrics.accuracy_score(y_test, i))\n",
    "print(keep2)\n",
    "final2 = []\n",
    "for i in range(len(better_model2[0])):\n",
    "       keep2 = np.zeros(22)\n",
    "       for x in range(len(better_model2)):\n",
    "              keep2 += better_model2[x][i]\n",
    "       for i in range(len(keep2)):\n",
    "              if keep2[i] == max(keep2):\n",
    "                     keep2[i] = 1\n",
    "              else:\n",
    "                     keep2[i] = 0\n",
    "       final2.append(keep2)\n",
    "final_array2 = np.array(final2)\n",
    "\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, final_array2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_model_trial_all_in_one(some_data, est, num):\n",
    "    model3 = RandomForestClassifier(n_estimators= est)\n",
    "    keep = []\n",
    "    the_models2 = []\n",
    "    feature_list= [['duration', 'peak_frequency', 'central_freq', 'snr'],\n",
    "                    ['duration', 'peak_frequency', 'snr', 'bandwidth'],\n",
    "                    ['duration', 'peak_frequency', 'central_freq', 'amplitude', 'snr'],\n",
    "                    ['duration', 'peak_frequency', 'amplitude', 'snr', 'bandwidth'],\n",
    "                    ['duration', 'peak_frequency', 'central_freq', 'amplitude', 'snr', 'bandwidth']]\n",
    "    #feature_list = list(combinations(some_data,3)) + list(combinations(some_data,4)) + list(combinations(some_data,5)) + list(combinations(some_data,6))\n",
    "    #feature_list =  list(combinations(some_data,4)) + list(combinations(some_data,5)) + list(combinations(some_data,6))\n",
    "\n",
    "    for i in feature_list:\n",
    "        \n",
    "        x_train = np.array(list(np.array(data_train[np.array(i)])) + list(np.array(data_val[np.array(i)])))\n",
    "        scaler = StandardScaler().fit(x_train)\n",
    "        standardized_X = scaler.transform(x_train)\n",
    "        scaler2 = Normalizer().fit(standardized_X)\n",
    "        std_and_norm_X_train = scaler2.transform(standardized_X)\n",
    "        \n",
    "        x_test = np.array(data_test[np.array(i)])\n",
    "        standardized_X_test = scaler.transform(x_test)\n",
    "        std_and_norm_X_test = scaler2.transform(standardized_X_test)\n",
    "\n",
    "        #no change\n",
    "        #model3.fit(x_train, y_train)\n",
    "        #y_predict = model3.predict(x_test)\n",
    "        \n",
    "        #std \n",
    "        model3.fit(standardized_X, y_train)\n",
    "        y_predict = model3.predict(standardized_X_test)\n",
    "        \n",
    "        #std and norm\n",
    "        #model3.fit(std_and_norm_X_train, y_train)\n",
    "        #y_predict = model3.predict(std_and_norm_X_test)\n",
    "    #put all the models predictions into a list\n",
    "    #TODO need to store models for later\n",
    "        the_models2 += [y_predict]\n",
    "\n",
    "    #store the models scores in a list\n",
    "    model_score = []\n",
    "    for i in the_models2:\n",
    "        model_score.append(metrics.accuracy_score(y_test, i))  \n",
    "\n",
    "    #pick out the models with the highest scores\n",
    "    better_model3 = []\n",
    "    for i in range(len(model_score)):\n",
    "        if model_score[i] > num * max(model_score):\n",
    "            better_model3.append(the_models2[i])\n",
    "\n",
    "   #put the models back together by having them vote on each prediction     \n",
    "    final2 = []\n",
    "    for i in range(len(better_model3[0])):\n",
    "        keep2 = np.zeros(22)\n",
    "        for x in range(len(better_model3)):\n",
    "            keep2 += better_model3[x][i]\n",
    "        for i in range(len(keep2)):\n",
    "            if keep2[i] == max(keep2):\n",
    "                keep2[i] = 1\n",
    "            else:\n",
    "                keep2[i] = 0\n",
    "        final2.append(keep2)\n",
    "    final_array2 = np.array(final2)\n",
    "\n",
    "    return metrics.accuracy_score(y_test, final_array2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "0.8490245971162002\n"
    }
   ],
   "source": [
    "the_models2 = multi_model_trial_all_in_one(column_selection, 12, .5)\n",
    "print(the_models2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n48\n49\n50\n"
    }
   ],
   "source": [
    "multi_model_list = []\n",
    "for i in range(1,51):\n",
    "    multi_model_list.append(multi_model_trial_all_in_one(column_selection, i, .5))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "[0.6598812553011026, 0.8006785411365565, 0.7599660729431722, 0.8269720101781171, 0.804919423240034, 0.8396946564885496, 0.8057675996607294, 0.8371501272264631, 0.825275657336726, 0.8439355385920272, 0.8379983036471587, 0.8430873621713316, 0.8396946564885496, 0.8498727735368957, 0.8422391857506362, 0.8532654792196777, 0.8456318914334181, 0.8558100084817643, 0.8524173027989822, 0.8498727735368957, 0.8515691263782866, 0.8473282442748091, 0.8498727735368957, 0.8549618320610687, 0.8524173027989822, 0.8541136556403732, 0.8464800678541137, 0.8464800678541137, 0.8541136556403732, 0.8507209499575912, 0.8490245971162002, 0.8558100084817643, 0.8558100084817643, 0.8566581849024597, 0.8490245971162002, 0.8583545377438507, 0.8524173027989822, 0.8549618320610687, 0.8507209499575912, 0.8541136556403732, 0.8541136556403732, 0.8507209499575912, 0.8566581849024597, 0.8549618320610687, 0.8532654792196777, 0.8524173027989822, 0.8558100084817643, 0.8515691263782866, 0.8549618320610687, 0.8583545377438507]\n"
    }
   ],
   "source": [
    "print(multi_model_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_model(some_data, est):\n",
    "    model3 = RandomForestClassifier(n_estimators= est)\n",
    "    feature_list = ['duration', 'peak_frequency', 'central_freq', 'amplitude', 'snr', 'bandwidth']\n",
    "    scaler = StandardScaler().fit(x_train)\n",
    "    standardized_X = scaler.transform(x_train)\n",
    "    standardized_X_test = scaler.transform(x_test)\n",
    "\n",
    "    model3.fit(standardized_X, y_train)\n",
    "    y_predict = model3.predict(standardized_X_test)\n",
    "    return metrics.accuracy_score(y_test,y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_model_list2 = []\n",
    "#single_model_list.append([1,single_model(column_selection, 1)])\n",
    "for i in range(1,129):\n",
    "    single_model_list2.append(single_model(column_selection, 2*i))\n",
    "multi_model_list = []\n",
    "for i in range(1,129):\n",
    "    multi_model_list.append(multi_model_trial_all_in_one(column_selection, 2*i, .5))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "[[1, 0.7540288379983037], 0.6581849024597116, 0.7506361323155216, 0.7862595419847328, 0.8040712468193384, 0.7921967769296013, 0.8142493638676844, 0.8083121289228159, 0.813401187446989, 0.8193384223918575, 0.820186598812553, 0.8286683630195081, 0.821882951653944, 0.8303647158608991, 0.8227311280746396, 0.825275657336726, 0.81509754028838, 0.821882951653944, 0.820186598812553, 0.8269720101781171, 0.821882951653944, 0.825275657336726, 0.823579304495335, 0.8244274809160306, 0.8244274809160306, 0.8278201865988125, 0.8286683630195081, 0.8312128922815946, 0.8295165394402035, 0.833757421543681, 0.8329092451229856, 0.8286683630195081, 0.8244274809160306, 0.8278201865988125, 0.8295165394402035, 0.825275657336726, 0.825275657336726, 0.8286683630195081, 0.8286683630195081, 0.8269720101781171, 0.8286683630195081, 0.8329092451229856, 0.8303647158608991, 0.8286683630195081, 0.8329092451229856, 0.8388464800678541, 0.8354537743850721, 0.825275657336726, 0.825275657336726, 0.8329092451229856]\n"
    }
   ],
   "source": [
    "print(single_model_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "[0.7803223070398643, 0.6980491942324003, 0.7981340118744699, 0.741306191687871, 0.823579304495335, 0.7777777777777778, 0.820186598812553, 0.7828668363019508, 0.8286683630195081, 0.8057675996607294, 0.821882951653944, 0.8006785411365565, 0.8227311280746396, 0.8083121289228159, 0.825275657336726, 0.820186598812553, 0.8320610687022901, 0.8142493638676844, 0.8244274809160306, 0.8193384223918575, 0.8244274809160306, 0.8100084817642069, 0.8371501272264631, 0.8210347752332485, 0.8295165394402035, 0.816793893129771, 0.8312128922815946, 0.8227311280746396, 0.8286683630195081, 0.8278201865988125, 0.8312128922815946, 0.81509754028838, 0.8312128922815946, 0.823579304495335, 0.8278201865988125, 0.825275657336726, 0.8278201865988125, 0.8295165394402035, 0.8346055979643766, 0.821882951653944, 0.8320610687022901, 0.8210347752332485, 0.8354537743850721, 0.821882951653944, 0.8379983036471587, 0.8269720101781171, 0.8312128922815946, 0.823579304495335, 0.8346055979643766, 0.8286683630195081]\n"
    }
   ],
   "source": [
    "print(single_model_list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_model_list = np.array(multi_model_list)\n",
    "df = pd.DataFrame(multi_model_list, columns=[\"score\"])\n",
    "df.to_csv('multi_model2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_model_list = np.array(single_model_list)\n",
    "df = pd.DataFrame(single_model_list, columns=[\"score\"])\n",
    "df.to_csv('single_model2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "[0.81085666 0.82866836 0.83375742 0.84308736 0.8379983  0.84393554\n 0.84817642 0.84648007 0.85072095 0.84393554 0.8490246  0.8524173\n 0.85496183 0.85156913 0.84648007 0.84987277 0.85665818 0.85326548\n 0.85835454 0.85326548 0.85326548 0.85496183 0.85835454 0.85496183\n 0.86005089 0.85072095 0.85665818 0.85581001 0.8634436  0.85665818\n 0.85750636 0.8524173  0.85496183 0.85326548 0.85581001 0.85665818\n 0.85750636 0.85750636 0.85835454 0.85411366 0.85496183 0.85665818\n 0.85750636 0.85411366 0.85835454 0.85156913 0.86259542 0.85326548\n 0.85581001 0.85665818 0.86005089 0.85496183 0.85581001 0.85581001\n 0.85750636 0.85835454 0.85920271 0.85072095 0.85496183 0.85750636\n 0.85156913 0.8524173  0.85156913 0.85835454 0.85920271 0.85411366\n 0.85581001 0.85326548 0.86005089 0.8524173  0.85496183 0.85920271\n 0.85496183 0.85156913 0.85072095 0.85750636 0.85496183 0.85665818\n 0.85326548 0.8524173  0.85496183 0.85835454 0.86089907 0.85750636\n 0.84987277 0.85581001 0.85920271 0.85750636 0.85496183 0.85920271\n 0.85750636 0.85326548 0.85496183 0.8524173  0.85750636 0.85411366\n 0.85411366 0.85750636 0.85581001 0.85326548 0.85581001 0.85411366\n 0.85496183 0.86089907 0.85411366 0.85750636 0.85750636 0.85835454\n 0.85581001 0.85665818 0.85326548 0.85665818 0.85581001 0.85496183\n 0.85326548 0.85750636 0.85750636 0.85750636 0.8524173  0.85411366\n 0.85835454 0.85835454 0.85750636 0.85665818 0.85411366 0.85581001\n 0.85665818 0.85920271]\n[list([1, 0.7540288379983037]) 0.6581849024597116 0.7506361323155216\n 0.7862595419847328 0.8040712468193384 0.7921967769296013\n 0.8142493638676844 0.8083121289228159 0.813401187446989\n 0.8193384223918575 0.820186598812553 0.8286683630195081 0.821882951653944\n 0.8303647158608991 0.8227311280746396 0.825275657336726 0.81509754028838\n 0.821882951653944 0.820186598812553 0.8269720101781171 0.821882951653944\n 0.825275657336726 0.823579304495335 0.8244274809160306 0.8244274809160306\n 0.8278201865988125 0.8286683630195081 0.8312128922815946\n 0.8295165394402035 0.833757421543681 0.8329092451229856\n 0.8286683630195081 0.8244274809160306 0.8278201865988125\n 0.8295165394402035 0.825275657336726 0.825275657336726 0.8286683630195081\n 0.8286683630195081 0.8269720101781171 0.8286683630195081\n 0.8329092451229856 0.8303647158608991 0.8286683630195081\n 0.8329092451229856 0.8388464800678541 0.8354537743850721\n 0.825275657336726 0.825275657336726 0.8329092451229856]\n"
    }
   ],
   "source": [
    "print(multi_model_list)\n",
    "print(single_model_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}