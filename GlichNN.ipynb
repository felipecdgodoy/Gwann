{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#turns str glich name into a 1 or 0\n",
    "def gliches_get_stiches(aList,glich):\n",
    "    new_list = []\n",
    "    for i in range(len(aList)):\n",
    "        if aList[i] == glich:\n",
    "            new_list += [1]\n",
    "        else:\n",
    "            new_list += [0]\n",
    "    return np.array(new_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('trainingset_v1d1_metadata.csv')\n",
    "\n",
    "#glich to test\n",
    "glich = 'Whistle'\n",
    "\n",
    "#what features do we want \n",
    "column_selection = [\"duration\",\"peak_frequency\",\"central_freq\",\"amplitude\"]\n",
    "\n",
    "\n",
    "#training data\n",
    "data_train = data[data['sample_type'] == 'train']\n",
    "glich_list = data_train['label'].tolist()\n",
    "y_train = gliches_get_stiches(glich_list,glich)\n",
    "x_train = np.array(data_train[column_selection])\n",
    "\n",
    "#testing data\n",
    "data_test = data[data['sample_type'] == 'test']\n",
    "glich_list2 = data_test['label'].tolist()\n",
    "y_test = gliches_get_stiches(glich_list2,glich)\n",
    "x_test = np.array(data_test[column_selection])\n",
    "\n",
    "#validation data\n",
    "data_val = data[data['sample_type'] == 'validation']\n",
    "glich_list3 = data_val['label'].tolist()\n",
    "y_val = gliches_get_stiches(glich_list3,glich)\n",
    "x_val = np.array(data_val[column_selection])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(y,y_pred):\n",
    "    return np.mean(np.abs(y-y_pred)/y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_len = len(column_selection)\n",
    "model.add(keras.layers.Dense(50, input_dim=input_len, activation='relu'))\n",
    "model.add(keras.layers.Dense(50, activation='relu'))\n",
    "#model.add(keras.layers.Dropout(rate)) \n",
    "model.add(keras.layers.ActivityRegularization(l1=0.0, l2=0.0)) \n",
    "model.add(keras.layers.BatchNormalization())\n",
    "model.add(keras.layers.Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "callbacks = [EarlyStopping(monitor='val_loss', patience=20),\n",
    "            ModelCheckpoint(filepath='best_model.h5',\n",
    "                            monitor='val_loss',\n",
    "                            save_best_only=True,\n",
    "                           verbose=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5587 samples, validate on 1200 samples\n",
      "Epoch 1/200\n",
      "5587/5587 [==============================] - 3s 613us/step - loss: 0.0539 - val_loss: 0.1245\n",
      "Epoch 2/200\n",
      "5587/5587 [==============================] - 0s 85us/step - loss: 0.0345 - val_loss: 0.0541\n",
      "Epoch 3/200\n",
      "5587/5587 [==============================] - 0s 87us/step - loss: 0.0341 - val_loss: 0.0456\n",
      "Epoch 4/200\n",
      "5587/5587 [==============================] - 0s 77us/step - loss: 0.0338 - val_loss: 0.0391\n",
      "Epoch 5/200\n",
      "5587/5587 [==============================] - 0s 71us/step - loss: 0.0334 - val_loss: 0.0374\n",
      "Epoch 6/200\n",
      "5587/5587 [==============================] - 0s 71us/step - loss: 0.0329 - val_loss: 0.0344\n",
      "Epoch 7/200\n",
      "5587/5587 [==============================] - 0s 88us/step - loss: 0.0325 - val_loss: 0.0372\n",
      "Epoch 8/200\n",
      "5587/5587 [==============================] - 0s 80us/step - loss: 0.0304 - val_loss: 0.0372\n",
      "Epoch 9/200\n",
      "5587/5587 [==============================] - 0s 80us/step - loss: 0.0296 - val_loss: 0.0340\n",
      "Epoch 10/200\n",
      "5587/5587 [==============================] - 0s 76us/step - loss: 0.0295 - val_loss: 0.0446\n",
      "Epoch 11/200\n",
      "5587/5587 [==============================] - 0s 81us/step - loss: 0.0293 - val_loss: 0.0389\n",
      "Epoch 12/200\n",
      "5587/5587 [==============================] - 0s 74us/step - loss: 0.0289 - val_loss: 0.0443\n",
      "Epoch 13/200\n",
      "5587/5587 [==============================] - 0s 73us/step - loss: 0.0294 - val_loss: 0.0546\n",
      "Epoch 14/200\n",
      "5587/5587 [==============================] - 0s 71us/step - loss: 0.0441 - val_loss: 2.4535\n",
      "Epoch 15/200\n",
      "5587/5587 [==============================] - 0s 75us/step - loss: 0.0302 - val_loss: 0.2508\n",
      "Epoch 16/200\n",
      "5587/5587 [==============================] - 0s 72us/step - loss: 0.0343 - val_loss: 0.1286\n",
      "Epoch 17/200\n",
      "5587/5587 [==============================] - 0s 84us/step - loss: 0.0355 - val_loss: 0.1747\n",
      "Epoch 18/200\n",
      "5587/5587 [==============================] - 0s 81us/step - loss: 0.0349 - val_loss: 0.0569\n",
      "Epoch 19/200\n",
      "5587/5587 [==============================] - 0s 72us/step - loss: 0.0349 - val_loss: 0.0459\n",
      "Epoch 20/200\n",
      "5587/5587 [==============================] - 0s 77us/step - loss: 0.0351 - val_loss: 0.0384\n",
      "Epoch 21/200\n",
      "5587/5587 [==============================] - 0s 74us/step - loss: 0.0348 - val_loss: 0.0377\n",
      "Epoch 22/200\n",
      "5587/5587 [==============================] - 0s 71us/step - loss: 0.0349 - val_loss: 0.0363\n",
      "Epoch 23/200\n",
      "5587/5587 [==============================] - 0s 87us/step - loss: 0.0348 - val_loss: 0.0361\n",
      "Epoch 24/200\n",
      "5587/5587 [==============================] - 0s 81us/step - loss: 0.0348 - val_loss: 0.0358\n",
      "Epoch 25/200\n",
      "5587/5587 [==============================] - 0s 81us/step - loss: 0.0348 - val_loss: 0.0357\n",
      "Epoch 26/200\n",
      "5587/5587 [==============================] - ETA: 0s - loss: 0.034 - 0s 82us/step - loss: 0.0347 - val_loss: 0.0356\n",
      "Epoch 27/200\n",
      "5587/5587 [==============================] - 0s 86us/step - loss: 0.0349 - val_loss: 0.0356\n",
      "Epoch 28/200\n",
      "5587/5587 [==============================] - 0s 84us/step - loss: 0.0348 - val_loss: 0.0353\n",
      "Epoch 29/200\n",
      "5587/5587 [==============================] - 0s 83us/step - loss: 0.0347 - val_loss: 0.0357\n",
      "Epoch 30/200\n",
      "5587/5587 [==============================] - 0s 82us/step - loss: 0.0346 - val_loss: 0.0353\n",
      "Epoch 31/200\n",
      "5587/5587 [==============================] - 0s 76us/step - loss: 0.0346 - val_loss: 0.0353\n",
      "Epoch 32/200\n",
      "5587/5587 [==============================] - 0s 75us/step - loss: 0.0345 - val_loss: 0.0363\n",
      "Epoch 33/200\n",
      "5587/5587 [==============================] - 0s 75us/step - loss: 0.0348 - val_loss: 0.0352\n",
      "Epoch 34/200\n",
      "5587/5587 [==============================] - 0s 85us/step - loss: 0.0345 - val_loss: 0.0355\n",
      "Epoch 35/200\n",
      "5587/5587 [==============================] - 0s 81us/step - loss: 0.0346 - val_loss: 0.0351\n",
      "Epoch 36/200\n",
      "5587/5587 [==============================] - 0s 75us/step - loss: 0.0346 - val_loss: 0.0351\n",
      "Epoch 37/200\n",
      "5587/5587 [==============================] - 0s 77us/step - loss: 0.0346 - val_loss: 0.0352\n",
      "Epoch 38/200\n",
      "5587/5587 [==============================] - 0s 73us/step - loss: 0.0344 - val_loss: 0.0352\n",
      "Epoch 39/200\n",
      "5587/5587 [==============================] - 0s 73us/step - loss: 0.0344 - val_loss: 0.0352\n",
      "Epoch 40/200\n",
      "5587/5587 [==============================] - 0s 75us/step - loss: 0.0343 - val_loss: 0.0356\n",
      "Epoch 41/200\n",
      "5587/5587 [==============================] - 0s 79us/step - loss: 0.0344 - val_loss: 0.0349\n",
      "Epoch 42/200\n",
      "5587/5587 [==============================] - 0s 71us/step - loss: 0.0346 - val_loss: 0.0349\n",
      "Epoch 43/200\n",
      "5587/5587 [==============================] - 0s 77us/step - loss: 0.0345 - val_loss: 0.0367\n",
      "Epoch 44/200\n",
      "5587/5587 [==============================] - 0s 81us/step - loss: 0.0345 - val_loss: 0.0347\n",
      "Epoch 45/200\n",
      "5587/5587 [==============================] - 1s 93us/step - loss: 0.0342 - val_loss: 0.0347\n",
      "Epoch 46/200\n",
      "5587/5587 [==============================] - 0s 79us/step - loss: 0.0341 - val_loss: 0.0346\n",
      "Epoch 47/200\n",
      "5587/5587 [==============================] - 0s 78us/step - loss: 0.0340 - val_loss: 0.0345\n",
      "Epoch 48/200\n",
      "5587/5587 [==============================] - 0s 77us/step - loss: 0.0339 - val_loss: 0.0345\n",
      "Epoch 49/200\n",
      "5587/5587 [==============================] - 0s 80us/step - loss: 0.0338 - val_loss: 0.0352\n",
      "Epoch 50/200\n",
      "5587/5587 [==============================] - 0s 81us/step - loss: 0.0339 - val_loss: 0.0343\n",
      "Epoch 51/200\n",
      "5587/5587 [==============================] - 0s 78us/step - loss: 0.0339 - val_loss: 0.0344\n",
      "Epoch 52/200\n",
      "5587/5587 [==============================] - 0s 76us/step - loss: 0.0337 - val_loss: 0.0340\n",
      "Epoch 53/200\n",
      "5587/5587 [==============================] - 0s 76us/step - loss: 0.0334 - val_loss: 0.0341\n",
      "Epoch 54/200\n",
      "5587/5587 [==============================] - 0s 62us/step - loss: 0.0334 - val_loss: 0.0335\n",
      "Epoch 55/200\n",
      "5587/5587 [==============================] - 0s 69us/step - loss: 0.0331 - val_loss: 0.0341\n",
      "Epoch 56/200\n",
      "5587/5587 [==============================] - 0s 89us/step - loss: 0.0331 - val_loss: 0.0327\n",
      "Epoch 57/200\n",
      "5587/5587 [==============================] - 0s 76us/step - loss: 0.0325 - val_loss: 0.0325\n",
      "Epoch 58/200\n",
      "5587/5587 [==============================] - 0s 74us/step - loss: 0.0324 - val_loss: 0.0333\n",
      "Epoch 59/200\n",
      "5587/5587 [==============================] - 0s 73us/step - loss: 0.0321 - val_loss: 0.0320\n",
      "Epoch 60/200\n",
      "5587/5587 [==============================] - 0s 72us/step - loss: 0.0322 - val_loss: 0.0321\n",
      "Epoch 61/200\n",
      "5587/5587 [==============================] - 0s 84us/step - loss: 0.0320 - val_loss: 0.0322\n",
      "Epoch 62/200\n",
      "5587/5587 [==============================] - 0s 78us/step - loss: 0.0316 - val_loss: 0.0310\n",
      "Epoch 63/200\n",
      "5587/5587 [==============================] - 0s 75us/step - loss: 0.0313 - val_loss: 0.0356\n",
      "Epoch 64/200\n",
      "5587/5587 [==============================] - 0s 84us/step - loss: 0.0311 - val_loss: 0.0308\n",
      "Epoch 65/200\n",
      "5587/5587 [==============================] - 0s 81us/step - loss: 0.0308 - val_loss: 0.0311\n",
      "Epoch 66/200\n",
      "5587/5587 [==============================] - 0s 79us/step - loss: 0.0305 - val_loss: 0.0303\n",
      "Epoch 67/200\n",
      "5587/5587 [==============================] - 0s 78us/step - loss: 0.0296 - val_loss: 0.8930\n",
      "Epoch 68/200\n",
      "5587/5587 [==============================] - 1s 101us/step - loss: 0.0308 - val_loss: 0.2758\n",
      "Epoch 69/200\n",
      "5587/5587 [==============================] - 0s 75us/step - loss: 0.0299 - val_loss: 0.1232\n",
      "Epoch 70/200\n",
      "5587/5587 [==============================] - 1s 96us/step - loss: 0.0302 - val_loss: 0.0674\n",
      "Epoch 71/200\n",
      "5587/5587 [==============================] - 0s 73us/step - loss: 0.0294 - val_loss: 0.0346\n",
      "Epoch 72/200\n",
      "5587/5587 [==============================] - 0s 71us/step - loss: 0.0294 - val_loss: 0.0319\n",
      "Epoch 73/200\n",
      "5587/5587 [==============================] - 0s 73us/step - loss: 0.0293 - val_loss: 0.0294\n",
      "Epoch 74/200\n",
      "5587/5587 [==============================] - 0s 73us/step - loss: 0.0291 - val_loss: 0.0285\n",
      "Epoch 75/200\n",
      "5587/5587 [==============================] - 0s 74us/step - loss: 0.0294 - val_loss: 0.0291\n",
      "Epoch 76/200\n",
      "5587/5587 [==============================] - 0s 74us/step - loss: 0.0295 - val_loss: 0.0284\n",
      "Epoch 77/200\n",
      "5587/5587 [==============================] - 0s 73us/step - loss: 0.0292 - val_loss: 0.0305\n",
      "Epoch 78/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5587/5587 [==============================] - 0s 75us/step - loss: 0.0290 - val_loss: 0.0284\n",
      "Epoch 79/200\n",
      "5587/5587 [==============================] - 0s 74us/step - loss: 0.0292 - val_loss: 0.0287\n",
      "Epoch 80/200\n",
      "5587/5587 [==============================] - 0s 70us/step - loss: 0.0289 - val_loss: 0.0281\n",
      "Epoch 81/200\n",
      "5587/5587 [==============================] - 0s 66us/step - loss: 0.0293 - val_loss: 0.0282\n",
      "Epoch 82/200\n",
      "5587/5587 [==============================] - 0s 72us/step - loss: 0.0290 - val_loss: 0.0285\n",
      "Epoch 83/200\n",
      "5587/5587 [==============================] - 0s 71us/step - loss: 0.0287 - val_loss: 0.0280\n",
      "Epoch 84/200\n",
      "5587/5587 [==============================] - 0s 71us/step - loss: 0.0292 - val_loss: 0.0277\n",
      "Epoch 85/200\n",
      "5587/5587 [==============================] - 0s 81us/step - loss: 0.0288 - val_loss: 0.0278\n",
      "Epoch 86/200\n",
      "5587/5587 [==============================] - 0s 71us/step - loss: 0.0282 - val_loss: 0.0277\n",
      "Epoch 87/200\n",
      "5587/5587 [==============================] - 0s 73us/step - loss: 0.0283 - val_loss: 0.0279\n",
      "Epoch 88/200\n",
      "5587/5587 [==============================] - 0s 74us/step - loss: 0.0287 - val_loss: 0.0280\n",
      "Epoch 89/200\n",
      "5587/5587 [==============================] - 0s 70us/step - loss: 0.0287 - val_loss: 0.0277\n",
      "Epoch 90/200\n",
      "5587/5587 [==============================] - 0s 75us/step - loss: 0.0288 - val_loss: 0.0276\n",
      "Epoch 91/200\n",
      "5587/5587 [==============================] - 0s 85us/step - loss: 0.0282 - val_loss: 0.0276\n",
      "Epoch 92/200\n",
      "5587/5587 [==============================] - 0s 78us/step - loss: 0.0287 - val_loss: 0.0275\n",
      "Epoch 93/200\n",
      "5587/5587 [==============================] - 0s 75us/step - loss: 0.0283 - val_loss: 0.0282\n",
      "Epoch 94/200\n",
      "5587/5587 [==============================] - 0s 68us/step - loss: 0.0281 - val_loss: 0.0286\n",
      "Epoch 95/200\n",
      "5587/5587 [==============================] - 0s 73us/step - loss: 0.0283 - val_loss: 0.0275\n",
      "Epoch 96/200\n",
      "5587/5587 [==============================] - 0s 74us/step - loss: 0.0285 - val_loss: 0.0275\n",
      "Epoch 97/200\n",
      "5587/5587 [==============================] - 0s 73us/step - loss: 0.0283 - val_loss: 0.0277\n",
      "Epoch 98/200\n",
      "5587/5587 [==============================] - 0s 76us/step - loss: 0.0287 - val_loss: 0.0274\n",
      "Epoch 99/200\n",
      "5587/5587 [==============================] - 0s 73us/step - loss: 0.0284 - val_loss: 0.0278\n",
      "Epoch 100/200\n",
      "5587/5587 [==============================] - 0s 76us/step - loss: 0.0290 - val_loss: 0.0273\n",
      "Epoch 101/200\n",
      "5587/5587 [==============================] - 0s 73us/step - loss: 0.0291 - val_loss: 0.0283\n",
      "Epoch 102/200\n",
      "5587/5587 [==============================] - 0s 77us/step - loss: 0.0285 - val_loss: 0.0277\n",
      "Epoch 103/200\n",
      "5587/5587 [==============================] - 1s 91us/step - loss: 0.0281 - val_loss: 0.0283\n",
      "Epoch 104/200\n",
      "5587/5587 [==============================] - 1s 91us/step - loss: 0.0286 - val_loss: 0.0277\n",
      "Epoch 105/200\n",
      "5587/5587 [==============================] - 0s 78us/step - loss: 0.0290 - val_loss: 0.0308\n",
      "Epoch 106/200\n",
      "5587/5587 [==============================] - 0s 74us/step - loss: 0.0282 - val_loss: 0.0275\n",
      "Epoch 107/200\n",
      "5587/5587 [==============================] - 0s 74us/step - loss: 0.0290 - val_loss: 0.0272\n",
      "Epoch 108/200\n",
      "5587/5587 [==============================] - 0s 74us/step - loss: 0.0283 - val_loss: 0.0277\n",
      "Epoch 109/200\n",
      "5587/5587 [==============================] - 0s 76us/step - loss: 0.0286 - val_loss: 0.0271\n",
      "Epoch 110/200\n",
      "5587/5587 [==============================] - 0s 75us/step - loss: 0.0281 - val_loss: 0.0280\n",
      "Epoch 111/200\n",
      "5587/5587 [==============================] - 0s 72us/step - loss: 0.0277 - val_loss: 0.0272\n",
      "Epoch 112/200\n",
      "5587/5587 [==============================] - 0s 72us/step - loss: 0.0281 - val_loss: 0.0270\n",
      "Epoch 113/200\n",
      "5587/5587 [==============================] - 0s 76us/step - loss: 0.0281 - val_loss: 0.0273\n",
      "Epoch 114/200\n",
      "5587/5587 [==============================] - 0s 80us/step - loss: 0.0282 - val_loss: 0.0271\n",
      "Epoch 115/200\n",
      "5587/5587 [==============================] - 0s 88us/step - loss: 0.0290 - val_loss: 0.0270\n",
      "Epoch 116/200\n",
      "5587/5587 [==============================] - 0s 86us/step - loss: 0.0285 - val_loss: 0.0274\n",
      "Epoch 117/200\n",
      "5587/5587 [==============================] - 0s 80us/step - loss: 0.0283 - val_loss: 0.0270\n",
      "Epoch 118/200\n",
      "5587/5587 [==============================] - 0s 78us/step - loss: 0.0281 - val_loss: 0.0269\n",
      "Epoch 119/200\n",
      "5587/5587 [==============================] - 0s 73us/step - loss: 0.0281 - val_loss: 0.0268\n",
      "Epoch 120/200\n",
      "5587/5587 [==============================] - 0s 75us/step - loss: 0.0278 - val_loss: 0.0271\n",
      "Epoch 121/200\n",
      "5587/5587 [==============================] - 0s 76us/step - loss: 0.0291 - val_loss: 0.0292\n",
      "Epoch 122/200\n",
      "5587/5587 [==============================] - 0s 75us/step - loss: 0.0289 - val_loss: 0.0268\n",
      "Epoch 123/200\n",
      "5587/5587 [==============================] - 0s 72us/step - loss: 0.0272 - val_loss: 0.0267\n",
      "Epoch 124/200\n",
      "5587/5587 [==============================] - 0s 75us/step - loss: 0.0274 - val_loss: 0.0270\n",
      "Epoch 125/200\n",
      "5587/5587 [==============================] - 0s 72us/step - loss: 0.0281 - val_loss: 0.0268\n",
      "Epoch 126/200\n",
      "5587/5587 [==============================] - 0s 83us/step - loss: 0.0280 - val_loss: 0.0268\n",
      "Epoch 127/200\n",
      "5587/5587 [==============================] - 0s 78us/step - loss: 0.0276 - val_loss: 0.0273\n",
      "Epoch 128/200\n",
      "5587/5587 [==============================] - 0s 77us/step - loss: 0.0286 - val_loss: 0.0267\n",
      "Epoch 129/200\n",
      "5587/5587 [==============================] - 0s 75us/step - loss: 0.0285 - val_loss: 0.0269\n",
      "Epoch 130/200\n",
      "5587/5587 [==============================] - 0s 72us/step - loss: 0.0278 - val_loss: 0.0268\n",
      "Epoch 131/200\n",
      "5587/5587 [==============================] - 0s 75us/step - loss: 0.0277 - val_loss: 0.0267\n",
      "Epoch 132/200\n",
      "5587/5587 [==============================] - 0s 74us/step - loss: 0.0275 - val_loss: 0.0267\n",
      "Epoch 133/200\n",
      "5587/5587 [==============================] - 0s 75us/step - loss: 0.0281 - val_loss: 0.0271\n",
      "Epoch 134/200\n",
      "5587/5587 [==============================] - 0s 72us/step - loss: 0.0285 - val_loss: 0.0268\n",
      "Epoch 135/200\n",
      "5587/5587 [==============================] - 0s 74us/step - loss: 0.0275 - val_loss: 0.0274\n",
      "Epoch 136/200\n",
      "5587/5587 [==============================] - 0s 76us/step - loss: 0.0276 - val_loss: 0.0268\n",
      "Epoch 137/200\n",
      "5587/5587 [==============================] - 0s 76us/step - loss: 0.0276 - val_loss: 0.0268\n",
      "Epoch 138/200\n",
      "5587/5587 [==============================] - 0s 80us/step - loss: 0.0280 - val_loss: 0.0302\n",
      "Epoch 139/200\n",
      "5587/5587 [==============================] - 0s 73us/step - loss: 0.0279 - val_loss: 0.0268\n",
      "Epoch 140/200\n",
      "5587/5587 [==============================] - 0s 76us/step - loss: 0.0274 - val_loss: 0.0273\n",
      "Epoch 141/200\n",
      "5587/5587 [==============================] - 0s 75us/step - loss: 0.0275 - val_loss: 0.0267\n",
      "Epoch 142/200\n",
      "5587/5587 [==============================] - 0s 74us/step - loss: 0.0274 - val_loss: 0.0270\n",
      "Epoch 143/200\n",
      "5587/5587 [==============================] - 0s 77us/step - loss: 0.0285 - val_loss: 0.0265\n",
      "Epoch 144/200\n",
      "5587/5587 [==============================] - 0s 73us/step - loss: 0.0278 - val_loss: 0.0267\n",
      "Epoch 145/200\n",
      "5587/5587 [==============================] - 0s 78us/step - loss: 0.0279 - val_loss: 0.0266\n",
      "Epoch 146/200\n",
      "5587/5587 [==============================] - 0s 77us/step - loss: 0.0281 - val_loss: 0.0267\n",
      "Epoch 147/200\n",
      "5587/5587 [==============================] - 0s 72us/step - loss: 0.0277 - val_loss: 0.0265\n",
      "Epoch 148/200\n",
      "5587/5587 [==============================] - 0s 80us/step - loss: 0.0281 - val_loss: 0.0269\n",
      "Epoch 149/200\n",
      "5587/5587 [==============================] - 0s 80us/step - loss: 0.0271 - val_loss: 0.0278\n",
      "Epoch 150/200\n",
      "5587/5587 [==============================] - 0s 71us/step - loss: 0.0279 - val_loss: 0.0270\n",
      "Epoch 151/200\n",
      "5587/5587 [==============================] - 0s 70us/step - loss: 0.0291 - val_loss: 0.0267\n",
      "Epoch 152/200\n",
      "5587/5587 [==============================] - 0s 69us/step - loss: 0.0277 - val_loss: 0.0269\n",
      "Epoch 153/200\n",
      "5587/5587 [==============================] - ETA: 0s - loss: 0.028 - 0s 74us/step - loss: 0.0285 - val_loss: 0.0271\n",
      "Epoch 154/200\n",
      "5587/5587 [==============================] - 0s 73us/step - loss: 0.0278 - val_loss: 0.0264\n",
      "Epoch 155/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5587/5587 [==============================] - 0s 70us/step - loss: 0.0285 - val_loss: 0.0265\n",
      "Epoch 156/200\n",
      "5587/5587 [==============================] - 0s 65us/step - loss: 0.0274 - val_loss: 0.0265\n",
      "Epoch 157/200\n",
      "5587/5587 [==============================] - 0s 65us/step - loss: 0.0277 - val_loss: 0.0264\n",
      "Epoch 158/200\n",
      "5587/5587 [==============================] - 0s 62us/step - loss: 0.0280 - val_loss: 0.0290\n",
      "Epoch 159/200\n",
      "5587/5587 [==============================] - 0s 66us/step - loss: 0.0277 - val_loss: 0.0297\n",
      "Epoch 160/200\n",
      "5587/5587 [==============================] - 0s 71us/step - loss: 0.0277 - val_loss: 0.0264\n",
      "Epoch 161/200\n",
      "5587/5587 [==============================] - 0s 71us/step - loss: 0.0276 - val_loss: 0.0269\n",
      "Epoch 162/200\n",
      "5587/5587 [==============================] - 0s 89us/step - loss: 0.0280 - val_loss: 0.0315\n",
      "Epoch 163/200\n",
      "5587/5587 [==============================] - 0s 74us/step - loss: 0.0270 - val_loss: 0.0263\n",
      "Epoch 164/200\n",
      "5587/5587 [==============================] - 0s 76us/step - loss: 0.0276 - val_loss: 0.0266\n",
      "Epoch 165/200\n",
      "5587/5587 [==============================] - 0s 76us/step - loss: 0.0272 - val_loss: 0.0263\n",
      "Epoch 166/200\n",
      "5587/5587 [==============================] - 0s 72us/step - loss: 0.0270 - val_loss: 0.0263\n",
      "Epoch 167/200\n",
      "5587/5587 [==============================] - 0s 85us/step - loss: 0.0281 - val_loss: 0.0264\n",
      "Epoch 168/200\n",
      "5587/5587 [==============================] - 0s 82us/step - loss: 0.0275 - val_loss: 0.0269\n",
      "Epoch 169/200\n",
      "5587/5587 [==============================] - 1s 106us/step - loss: 0.0271 - val_loss: 0.0278\n",
      "Epoch 170/200\n",
      "5587/5587 [==============================] - 0s 78us/step - loss: 0.0295 - val_loss: 0.0285\n",
      "Epoch 171/200\n",
      "5587/5587 [==============================] - 0s 71us/step - loss: 0.0282 - val_loss: 0.0264\n",
      "Epoch 172/200\n",
      "5587/5587 [==============================] - 0s 77us/step - loss: 0.0273 - val_loss: 0.0271\n",
      "Epoch 173/200\n",
      "5587/5587 [==============================] - 0s 83us/step - loss: 0.0275 - val_loss: 0.0266\n",
      "Epoch 174/200\n",
      "5587/5587 [==============================] - 0s 71us/step - loss: 0.0270 - val_loss: 0.0262\n",
      "Epoch 175/200\n",
      "5587/5587 [==============================] - 0s 74us/step - loss: 0.0275 - val_loss: 0.0267\n",
      "Epoch 176/200\n",
      "5587/5587 [==============================] - 0s 73us/step - loss: 0.0269 - val_loss: 0.0264\n",
      "Epoch 177/200\n",
      "5587/5587 [==============================] - 0s 74us/step - loss: 0.0272 - val_loss: 0.0280\n",
      "Epoch 178/200\n",
      "5587/5587 [==============================] - 0s 74us/step - loss: 0.0272 - val_loss: 0.0264\n",
      "Epoch 179/200\n",
      "5587/5587 [==============================] - 0s 74us/step - loss: 0.0277 - val_loss: 0.0286\n",
      "Epoch 180/200\n",
      "5587/5587 [==============================] - 0s 79us/step - loss: 0.0275 - val_loss: 0.0342\n",
      "Epoch 181/200\n",
      "5587/5587 [==============================] - 0s 75us/step - loss: 0.0271 - val_loss: 0.0266\n",
      "Epoch 182/200\n",
      "5587/5587 [==============================] - 0s 80us/step - loss: 0.0284 - val_loss: 0.0332\n",
      "Epoch 183/200\n",
      "5587/5587 [==============================] - 0s 75us/step - loss: 0.0275 - val_loss: 0.0291\n",
      "Epoch 184/200\n",
      "5587/5587 [==============================] - 0s 78us/step - loss: 0.0266 - val_loss: 0.0285\n",
      "Epoch 185/200\n",
      "5587/5587 [==============================] - 0s 80us/step - loss: 0.0274 - val_loss: 0.0466\n",
      "Epoch 186/200\n",
      "5587/5587 [==============================] - 0s 76us/step - loss: 0.0273 - val_loss: 0.0349\n",
      "Epoch 187/200\n",
      "5587/5587 [==============================] - 0s 77us/step - loss: 0.0272 - val_loss: 0.0854\n",
      "Epoch 188/200\n",
      "5587/5587 [==============================] - 0s 75us/step - loss: 0.0382 - val_loss: 0.2361\n",
      "Epoch 189/200\n",
      "5587/5587 [==============================] - 0s 75us/step - loss: 0.0283 - val_loss: 0.0946\n",
      "Epoch 190/200\n",
      "5587/5587 [==============================] - 0s 74us/step - loss: 0.0273 - val_loss: 0.0531\n",
      "Epoch 191/200\n",
      "5587/5587 [==============================] - 0s 72us/step - loss: 0.0272 - val_loss: 0.0454\n",
      "Epoch 192/200\n",
      "5587/5587 [==============================] - 0s 74us/step - loss: 0.0277 - val_loss: 0.0416\n",
      "Epoch 193/200\n",
      "5587/5587 [==============================] - 0s 74us/step - loss: 0.0286 - val_loss: 0.0319\n",
      "Epoch 194/200\n",
      "5587/5587 [==============================] - 0s 75us/step - loss: 0.0274 - val_loss: 0.0275\n",
      "Epoch 195/200\n",
      "5587/5587 [==============================] - 0s 75us/step - loss: 0.0266 - val_loss: 0.0280\n",
      "Epoch 196/200\n",
      "5587/5587 [==============================] - 0s 80us/step - loss: 0.0273 - val_loss: 0.0284\n",
      "Epoch 197/200\n",
      "5587/5587 [==============================] - 0s 78us/step - loss: 0.0271 - val_loss: 0.0267\n",
      "Epoch 198/200\n",
      "5587/5587 [==============================] - 0s 72us/step - loss: 0.0277 - val_loss: 0.0292\n",
      "Epoch 199/200\n",
      "5587/5587 [==============================] - 0s 78us/step - loss: 0.0269 - val_loss: 0.0263\n",
      "Epoch 200/200\n",
      "5587/5587 [==============================] - 0s 75us/step - loss: 0.0275 - val_loss: 0.0265\n"
     ]
    }
   ],
   "source": [
    "#history = model.fit(x_train, y_train,\n",
    "#                        epochs=50, batch_size=128)\n",
    "history = model.fit(x_train, y_train,\n",
    "            epochs=200, \n",
    "            batch_size=128, \n",
    "            #callbacks=callbacks,\n",
    "            validation_data=(x_val, y_val)\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.677287125968072"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = model.predict(x_test)\n",
    "score(preds, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plot_loss(hist):\n",
    "    %matplotlib inline\n",
    "    plt.title('Training Curve')\n",
    "    plt.plot(hist.history['loss'], label='train')\n",
    "    plt.plot(hist.history['val_loss'], label='validation')\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Mean squared error\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "plot_loss(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
